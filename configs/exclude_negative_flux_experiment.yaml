"""
In this experiment, we exclude time-steps with negative measured flux in the dataset.
NOTE: It could be the opposite (the baseline would be exclude, this experiment could be include)
This one might be removed. Indeed, do we test on data with or without negative flux?
Without, it makes little sense (we just make the dataset easier to learn).
With, we can only expect results to be worse, as we didn't even give a chance to the model to learn
and adapt to some of the data distribution.
Also, the pipeline can predict negative flux, even though it's not always possible and depends on 
the global variables (too annoying to check when it's possible to predict the output LE using the pipeline,
amounts to a sensitivity study). But, perhaps rs is simply an proportional inversion of Q_LE assuming 
other parameters are fixed. Then, perhaps there's a chance. But it seems too much work.
"""

model:
    n_hidden : 4
    hidden_size : 64 # NOTE: Perhaps replace with an array describing layers?
    batch_norm : True # NOTE: Can't be True if batch_size==1. We may add an assertion for this
    activation : 'ReLU'

data: # (does it need to be nested?)
    sites : ["CH-Dav", "AR-Vir", "AU-Ade", "AU-Stp"] 
    base_path : "~/epfl/semester_project/databases/T_C_PIPELINE_DATA/"
    nPoints : 500 # -> decide if we want to truncate, what to do in training?
    exclude_negative : False

pipeline:
    use_vmax : False
    predict_rs: True # If false, we predict gsCO2 instead, and perform physical operations to obtain rs.

train:
    lr: 1e-3
    epochs: 1000
    weight_decay: 1e-4
    batch_size: 100
    test_split: 0.2
    hp_tuning: False # If this is true, hyperparameters are expected to be arrays.

wandb:
  use_wandb: False
  project: "change-project"
  tags: ['default_config']

model_weights_path: "model_weights/default_model.pt"